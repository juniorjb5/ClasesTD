---
title: "Modelo de regresi√≥n lineal"
subtitle: "<br/> Tema 1"
author: "PhD. Orlando Joaqui-Barandica"
institute: "Universidad del Valle"
date: "2024"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: 
      - default
      - rladies
      - rladies-fonts
      - fonts_mtheme.css
      - sidney.css
    seal: false  
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false

---


```{r setup, include = FALSE}
library(knitr)                              # paquete que trae funciones utiles para R Markdown
library(tidyverse)                          # paquete que trae varios paquetes comunes en el tidyverse
library(datos)                              # paquete que viene con datos populares traducidos al espa√±ol :)
library(shiny)
# opciones predeterminadas
knitr::opts_chunk$set(echo = FALSE,         # FALSE: los bloques de c√≥digo NO se muestran
                      dpi = 300,            # asegura gr√°ficos de alta resoluci√≥n
                      warning = FALSE,      # los mensajes de advertencia NO se muestran
                      error = FALSE)        # los mensajes de error NO se muestran


options(htmltools.dir.version = FALSE)
```

class: inverse, left, bottom
background-image: url("img/fondo.jpg")
background-size: cover


# **`r rmarkdown::metadata$title`**
----

## **`r rmarkdown::metadata$subtitle`**

### `r rmarkdown::metadata$author`
### `r rmarkdown::metadata$date`

```{r xaringanExtra-share-again, echo=FALSE}
xaringanExtra::use_share_again()
```

```{r xaringanExtra-clipboard, echo=FALSE}
xaringanExtra::use_clipboard()
```

---
name: hola
class: inverse, middle, center

# Universidad del Valle

--

## Maestr√≠a en Anal√≠tica e Inteligencia de Negocios


---




.pull-left[

<br><br><br><br><br>

```{r echo=FALSE, out.width = "110%" }
knitr::include_graphics("img/gif1.gif")
```
]

<br><br><br><br><br>


.pull-right[
# Orlando Joaqui-Barandica
### [www.joaquibarandica.com](https://www.joaquibarandica.com)
 *PhD.(C) in Industrial Engineering* 
 
 *MSc. Applied Economics*
 
 *BSc. Statistics*
]

---


name: Casos
class: inverse, center, middle

# `r icon("sort-numeric-up")`
# CASOS
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---


# Casos


.pull-left[

* .font110[Imagine que el gobierno lo contrata para evaluar la efectividad de un programa de capacitaci√≥n para el trabajo financiado con fondos p√∫blicos. Suponga que se trata de un programa para instruir a los trabajadores sobre diversas maneras de utilizar las computadoras en los procesos de fabricaci√≥n.]



* .font110[Este programa, de veinte semanas, ofrece cursos en horarios fuera de la jornada laboral. Cualquier trabajador de la industria puede participar e inscribirse de manera voluntaria a todo el programa o a una parte de √©l. ]

]

.pull-right[

.center[ 
### Usted tiene que determinar si este programa de capacitaci√≥n laboral tiene alg√∫n efecto sobre los posteriores salarios por hora de los trabajadores.


.orange[.font180[**¬øQu√© hacer?**]]]

<img src="https://media.giphy.com/media/BBkKEBJkmFbTG/giphy.gif" width="90%"/>

]


---


class: center, middle

### En este caso no se necesita una teor√≠a formal. Una comprensi√≥n b√°sica de la econom√≠a es suficiente para advertir que factores tales como la educaci√≥n, la experiencia y la capacitaci√≥n laboral afectan la productividad de los trabajadores.

--


### Los analistas saben que a los trabajadores se les paga en raz√≥n de su productividad

--

.brand-charcoal[.font150[$$salario = f(educ, exper, capacitaci√≥n)$$]]


.left[
D√≥nde,

- *salario* =  Salario por hora
- *educ* = a√±os de escolaridad formal
- *exper* =  a√±os de experiencia
- *capacitaci√≥n* = semanas de capacitaci√≥n laboral
]

.gray[.right[Claramente hay otros factores que influyen, <br> pero este planteamiento encierra la escencia del problema]]

---

class: center, middle, inverse
background-image: url(https://media.giphy.com/media/42HJ26S7bvbmVhcaR2/giphy.gif)
background-size: cover

# Qu√© caracter√≠sticas tiene cada una de las variables identificadas?

<br>

.white[.font180[$$salario = f(educ, exper, capacitaci√≥n)$$]]


---


# Casos


* .font150[Un proyecto de investigaci√≥n de la alcald√≠a de Cali quiere establecer los factores que influyen en que un ciudadano utilice o no el servicio del MIO.. ]

.center[.orange[.font180[**¬øQu√© hacer?**]]]

--

<br>

* .font150[El mismo proyecto anterior tiene una variante en su etapa IV de desarrollo. Ahora, se quiere establecer qu√© factores influyen para que un ciudadano se movilice en Moto, Carro y Servicio P√∫blico (Bus, MIO, Etc)...] 

.center[.orange[.font180[**¬øQu√© hacer?**]]]


---


# Casos


* .font150[Se desea modelar la percepci√≥n de la √∫ltima feria de Cali realizada en el 2017, la cu√°l fue evaluada mediante una encuesta socioecon√≥mica, en d√≥nde los encuestados calificaron entre `Muy buena`, `Buena`, `Regular` y `Mala`.]

.center[.orange[.font180[**¬øQu√© hacer?**]]]

--

<br>

* .font150[El observatorio econ√≥mico regional tiene el principal inter√©s de evaluar cuales son los factores que determinan la decisi√≥n de estudiar y trabajar de manera simult√°nea en los ciudadanos.] 

.center[.orange[.font180[**¬øQu√© hacer?**]]]


---


# Casos


* .font150[La responsabilidad social corporativa es un factor muy importante para las empresas. Por tal motivo las empresas divulgan informaci√≥n de sus actividades de tipo medio ambiental, laboral, comunidad, entre otras, a√±o tras a√±o. ¬øQu√© factores inciden en la divulgaci√≥n de informaci√≥n de RSC de las empresas durante los a√±os 2015 a 2018?]

.center[.orange[.font180[**¬øQu√© hacer?**]]]


---



name: Metodologia
class: inverse, center, middle

# `r icon("broom")`
# Metodolog√≠a de la modelaci√≥n
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---

class: center, middle, inverse
background-image: url(https://media.giphy.com/media/YK257LnLWgGR2/giphy.gif)
background-size: cover



# ¬øC√≥mo proceden los analistas en el an√°lisis de un problema? 

#Es decir, ¬øcu√°l es su metodolog√≠a?

---

# Metodolog√≠a


.font140[
> 1. .orange[Planteamiento de la teor√≠a o de la hip√≥tesis.]

> 2. Especificaci√≥n del modelo matem√°tico de la teor√≠a.

> 3. .orange[Especificaci√≥n del modelo estad√≠stico de la teor√≠a.]

> 4. Obtenci√≥n de datos.

> 5. .orange[Estimaci√≥n de los par√°metros del modelo]

> 6. Pruebas de hip√≥tesis.

> 7. .orange[Pron√≥stico o predicci√≥n.]

> 8. Utilizaci√≥n del modelo para fines de toma de decisiones.
]


---


# 1. Planteamiento de la teor√≠a o de la hip√≥tesis.


## Keynes plantea:

.font120[.orange[La ley psicol√≥gica fundamental‚Ä¶ consiste en que los hombres [y las mujeres], como regla general y en promedio, est√°n dispuestos a incrementar su consumo a medida que aumenta su ingreso, pero no en la misma cuant√≠a del aumento en su ingreso.]]



.pull-left[
----
### En pocas palabras, Keynes postula que la *propensi√≥n marginal a consumir* (PMC), es decir, la tasa de cambio del consumo generado por una unidad (digamos, un d√≥lar) de cambio en el ingreso, es mayor que cero pero menor que uno.
----
]


.pull-right[
.center[
<img src="https://media.giphy.com/media/3o6gDWzmAzrpi5DQU8/giphy.gif" width="80%"/>
]]



---


# 2. Especificaci√≥n del modelo matem√°tico de la teor√≠a.


## Keynes plantea:

.font120[.green[A pesar de haber postulado una relaci√≥n positiva entre el consumo y el ingreso, Keynes no especifica la forma precisa de la relaci√≥n funcional entre ambas cosas. Por simplicidad, un economista matem√°tico puede proponer la siguiente forma de la funci√≥n keynesiana de consumo:]]

.font140[$$Y = \beta_0 + \beta_1X$$]

donde $Y$ = gasto de consumo y $X$ = ingreso. El coeficiente de la pendiente $\beta_1$ mide la PMC. 

.center[
### Esta ecuaci√≥n plantea que el consumo esta relacionado linealmente con el ingreso, y es un ejemplo de un modelo matem√°tico de la relaci√≥n entre consumo e ingreso, llamada en econom√≠a funci√≥n  consumo.
]

---

# 3. Especificaci√≥n del modelo estad√≠stico de la teor√≠a.

.font120[Para dar cabida a relaciones inexactas entre las variables econ√≥micas, el analista modificar√≠a la funci√≥n determinista de consumo en la ecuaci√≥n de la siguiente manera:]

<br>

.font140[$$Y = \beta_0 + \beta_1X + u$$]

u: T√©rmino de perturbaci√≥n o de error, <br>
Variable aleatoria con propiedades probabil√≠sticas bien definidas. 

<br>

.font140[*El t√©rmino de perturbaci√≥n $u$ representa* **.orange[todos los factores]** *que afectan el consumo pero que* **no se consideran en el modelo en forma expl√≠cita**.]

---

# 4. Obtenci√≥n de datos

.font140[Para estimar el modelo se deben obtener los valores num√©ricos de] $\beta_0$ y $\beta_1$, .font140[para esto son necesarios los datos.]


.pull-left[
<br>

----

.orange[.font180[Ejemplo:]] .font120[se utilizan cifras relacionadas con la econom√≠a de Estados Unidos de 1960 a 2005. La variable *Y* es el gasto de consumo personal (GCP) agregado (para la econom√≠a en su conjunto), y la variable *X*, el producto interno bruto (PIB), una medida del ingreso agregado, ambos medidos en miles de millones de d√≥lares base a√±o 2000.]

----

]


.pull-right[
.center[
<img src="https://media.giphy.com/media/BombwjrdBX0hDTvhZ5/giphy.gif" width="60%"/>
]]




---


# 5. Estimaci√≥n de los par√°metros del modelo

.font120[El an√°lisis de regresi√≥n es la herramienta principal para obtener las estimaciones. Con esta t√©cnica y los datos obtuvimos los siguientes valores estimados de] $\beta_0$ y $\beta_1$, .font120[a saber, -299.5913 y 0.7218. As√≠, la funci√≥n consumo estimada es]

<br>

.font140[$$\hat{Y} = -299.5913 + 0.7218X$$]

>El coeficiente de la pendiente (es decir, la PMC) fue de alrededor de 0.72, lo que indica que:

<br>

### Para el periodo muestral un incremento de un d√≥lar en el ingreso real produjo, en promedio, un incremento cercano a 72 centavos en el gasto de consumo real. Decimos en **promedio** porque la relaci√≥n entre consumo e ingreso es inexacta.


---

# 6. Pruebas de Hip√≥tesis

.font120[En el supuesto de que el modelo ajustado sea una aproximaci√≥n razonablemente buena de la realidad, tenemos que establecer criterios apropiados para comprobar si los valores estimados obtenidos, por ejemplo, concuerdan con las expectativas de la teor√≠a que estamos probando.]

<br>

.center[
##Keynes esperaba que la PMC fuera positiva pero menor que 1. 
]

.font120[.orange[**En el ejemplo observamos que la PMC es alrededor de 0.72.** Pero antes de aceptar este resultado como confirmaci√≥n de la teor√≠a keynesiana de consumo, debemos averiguar si esta estimaci√≥n est√° lo bastante abajo de la unidad para convencernos de que no se trata de un suceso debido al azar o de una peculiaridad de los datos.] 

**En otras palabras,** ¬øEs 0.72 estad√≠sticamente menor que 1? Si lo es, puede apoyar la teor√≠a de Keynes.]


---

# 7. Pron√≥stico o predicci√≥n.

.font120[Suponga que queremos predecir la media del gasto de consumo para 2006. El valor del PIB para 2006 fue de 11 319.4 millones de d√≥lares.]

.font140[$$\hat{Y}_{2006} = -299.5913 + 0.7218(11319.4) = 7870.75$$]

----

> Con ese valor del PIB, la media o el promedio del gasto de consumo previsto es de alrededor de 7 870 millones de d√≥lares. El valor real del gasto de consumo registrado en 2006 fue de 8 044 millones de d√≥lares. 

----

.pull-left[
### El modelo estimado subpredijo el gasto de consumo real por casi 174 000 millones de d√≥lares.]

.pull-right[
Se dir√≠a que el error de predicci√≥n es de aproximadamente 174 000 millones de d√≥lares, que representa alrededor de 1.5% del valor real del PIB para 2006.
]

---

# 8. Utilizaci√≥n del modelo para toma de decisiones.

.center[
<img src="https://media.giphy.com/media/3o7qDSOvfaCO9b3MlO/giphy.gif" width="40%"/>
]

.center[
### Un modelo estimado sirve para fines de control o de pol√≠ticas p√∫blicas. Mediante una mezcla apropiada de pol√≠tica fiscal y monetaria, el gobierno puede manejar la variable de control X para producir el nivel deseado de la variable objetivo Y.
]


---




name: Causalidad
class: inverse, center, middle

# `r icon("dice-d6")`
# Causalidad
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---

# Causalidad

.font120[.green[A pesar de que el an√°lisis de regresi√≥n tiene que ver con la dependencia de una variable respecto de otras variables, esto no implica causalidad necesariamente.]]

<br>
.pull-left[

> .font120[`Una relaci√≥n estad√≠stica, por m√°s fuerte y sugerente que sea, nunca podr√° establecer una conexi√≥n causal: nuestras ideas de causalidad deben provenir de estad√≠sticas externas y, en √∫ltimo t√©rmino, de una u otra teor√≠a `]

]

.pull-right[
.center[
<img src="https://media.giphy.com/media/l2Je34w7WkZ84f3os/giphy.gif" width="95%"/>
]


]

---

class: inverse, center, middle
background-image: url(https://media.giphy.com/media/VdKEHcPsjrlQv9Cv5n/giphy.gif)
background-size: cover


# Causalidad

<br>
<br>

## En un ejemplo de rendimiento del cultivo, no hay una raz√≥n estad√≠stica para suponer que la lluvia no depende del rendimiento del cultivo.


## Considerar que el rendimiento del cultivo depende de la lluvia (entre otras cosas) se debe a cuestiones no estad√≠sticas: el sentido com√∫n indica que la relaci√≥n no puede ser a la inversa, pues no es posible controlar la lluvia mediante el rendimiento del cultivo.

---


# Causalidad

> .font140[En la mayor√≠a de las pruebas de teor√≠as econ√≥micas, as√≠ como en la evaluaci√≥n de pol√≠ticas p√∫blicas, **el objetivo de los analistas** es inferir que una variable (por ejemplo, la educaci√≥n) .orange[**tiene un efecto causal**] sobre otra variable (por ejemplo, la productividad de los trabajadores).]

<br> 
> .font140[Encontrar simplemente una relaci√≥n entre dos o m√°s variables puede ser sugestivo, pero no concluyente, a menos que pueda establecerse causalidad.]

<br>

> .font140[El concepto **ceteris paribus** ‚Äî.orange[**"si todos los dem√°s factores relevantes permanecen constantes"**]‚Äî tiene un papel importante en el an√°lisis causal.]

---


# Causalidad


.font180[$$salario = f(educ, exper, capacitaci√≥n)$$]

.font120[.orange[En este ejemplo, interesa conocer el efecto de una semana m√°s de capacitaci√≥n sobre el salario, cuando los dem√°s componentes en particular Educ y Exper, permanecen constantes.]]

- .font130[Si se logran mantener constantes todos los dem√°s factores relevantes...]
- .font130[... y se encuentra una relaci√≥n entre **capacitaci√≥n laboral** y **salarios**]

--

.center[
### Puede concluirse que tal capacitaci√≥n tiene un efecto causal sobre la productividad de los trabajadores.
]

.font120[A pesar de que esto puede parecer bastante sencillo, aun ya en este nivel inicial debe ser claro que, .green[**salvo en casos muy especiales, no ser√° posible mantener, literalmente, todo lo dem√°s sin cambio.**]]


---

# Causalidad

.font120[La pregunta fundamental en la mayor parte de los estudios emp√≠ricos es: ]

<br>
.center[
## ¬øse han mantenido constantes suficientes factores para que se justifique la causalidad?
]

<br>

- .font130[En la mayor√≠a de los casos, las hip√≥tesis en las ciencias sociales son de car√°cter ceteris paribus, es decir, para estudiar una relaci√≥n entre dos variables todos los dem√°s factores relevantes deben mantenerse constantes.]

- .font130[En las ciencias sociales, dado el car√°cter no experimental de la mayor parte de los datos que suelen recolectarse, hallar relaciones causales no es una tarea f√°cil.]


---

class: center, middle

# Datos experimentales $\neq$ Datos no experimentales

.font200[üö©üö©üö©]

---

name: TipoDatos
class: inverse, center, middle

# `r icon("database")`
# Tipos de datos
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---


# Tipos de datos

.pull-left[
### Las bases de datos estructurados pueden ser de diversos tipos. 

.font130[
>Aunque algunos m√©todos pueden ser empleados, con alguna o ninguna peque√±a modificaci√≥n, para distintos tipos de bases de datos, las caracter√≠sticas especiales de algunas bases de datos deben ser tomadas en cuenta y aprovecharse.]
]

.pull-right[
<br>
<br>
<br>
<br>
* ###Datos de corte transversal
* ###Datos de serie de tiempo
* ###Combinaci√≥n de cortes transversales
]

---



name: LinealSimple
class: inverse, center, middle

# `r icon("database")`
# An√°lisis de regresi√≥n lineal
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]




---

# An√°lisis de regresi√≥n lineal

<br>

El objetivo del an√°lisis de regresi√≥n es el de construir una funci√≥n que aproxime de la mejor manera el comportamiento de una variable aletoaria $(Y)$ a trav√©s del conocimiento previo del valor de una variable explicativa $(X)$, mediante una expresi√≥n lineal como la siguiente:

<br>

.font180[$$Y = \beta_0 + \beta_1X$$]

<br>

> - Y: es llamada la variable de respuesta o dependiente
> - X: es llamada la variable predictora o independiente
> - $\beta_0$: es el intercepto de la linea con el eje $Y$
> - $\beta_1$: es la pendiente de la linea de regresi√≥n



---

class: center

## Este modelo supone una **asociaci√≥n lineal** entre las variables de estudio, por tanto antes de empezar, esta relaci√≥n debe ser valorada


.pull-left[

```{r, warning=FALSE, echo=FALSE, message=FALSE, fig.height=5}


plot(iris$Petal.Length,iris$Petal.Width, main="Gr√°fico de dispersi√≥n")


# cor(iris$Petal.Length,iris$Petal.Width)


```


Correlaci√≥n entre `Petal.Length` y `Petal.Width` 0.96


]



.pull-right[

```{r, warning=FALSE, echo=FALSE, message=FALSE, fig.height=6.5}

library(ggcorrplot)

ggcorrplot(cor(iris[,-5]))

```



]


---

# An√°lisis de regresi√≥n lineal

<br>

El an√°lisis de regresi√≥n se relaciona en gran medida con la estimaci√≥n o predicci√≥n de la .orange[**media (de la poblaci√≥n) o valor promedio de la variable dependiente,**] con base en los valores conocidos o fijos de las variables explicativas.

<br>

> Las observaciones de la variable $Y$ (dependiente) se asumen aleatorias de una distribuci√≥n con media $E(Y|X=x)$. 

> Las desviaciones de las observaciones $y_i$ de la $E(Y|X=x)$ se tienen en cuenta adicionando un error aleatorio $u_i$ al siguiente modelo:

.font180[$$y_i = \beta_0 + \beta_1 x_i + u_i$$]


---

# Ejemplo

Estos datos se refieren a la poblaci√≥n total de 60 familias de una comunidad hipot√©tica, as√≠ como a su ingreso semanal $(X)$ y su gasto de consumo semanal $(Y)$, en d√≥lares. Las 60 familias se dividen en 10 grupos de ingresos (de 80 d√≥lares a 260); asimismo, aparecen los gastos semanales de cada familia de los diversos grupos. Por consiguiente, hay 10 valores fijos de $X$ y los correspondientes valores $Y$ para cada valor $X$; as√≠, hay 10 subpoblaciones $Y$.


.center[

<img src="img/ejm1.jpg" width="70%"/>

]


---

# Ejemplo

> En total hay 10 valores medios para las 10 subpoblaciones de Y. A estos valores medios se les llama valores esperados condicionales: $E(Y|X)$.

<br>

.pull-left[

Es importante distinguir entre los valores esperados condicionales y el valor esperado incondicional: $E(Y)$.


$$E(Y|X) \neq E(Y)$$



Si sumamos los consumos semanales de las 60 familias que forman la poblaci√≥n y dividimos este n√∫mero entre 60, obtendremos la cantidad de 121.20 d√≥lares (7272/60), que es el .orange[**valor de la media incondicional**], o esperada, del consumo semanal, $E(Y)$.

]

.pull-right[

.center[

<img src="https://media.giphy.com/media/hv53DaYcXWe3nRbR1A/giphy.gif" width="70%"/>

]

]


---

<br><br>

<img src="img/ejm2.jpg" width="90%"/>

### Esta figura muestra que para cada X (es decir, el nivel de ingresos) existe una poblaci√≥n de valores Y (consumo semanal) que se distribuyen alrededor de la media (condicional) de dichos valores Y.



---


name: MCO
class: inverse, center, middle

# `r icon("database")`
# M√≠nimos cuadrados ordinarios
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]

---


# Modelo de regresi√≥n lineal

<br>
<br>

Modelo especial en el que la descomposici√≥n ortogonal

<br>


.font200[$$Y = E(Y|X) + U$$]

<br>


> Es tal que $E(Y|X)$ es una funci√≥n lineal de $x_n$

> $Var(Y|X)$ es constante.


---

# Modelo de regresi√≥n lineal

<br>

.pull-left[

> .font140[Hay .orange[tres supuestos generales] de un modelo econom√©trico que garantizan la existencia de una descomposici√≥n ortogonal como la del modelo cl√°sico de regresi√≥n lineal.]

]

.pull-right[

.center[

## - Linealidad

## - Exogeneidad estricta

## - Perturbaciones esf√©ricas

]

]

---



# MCO


.font140[En el an√°lisis de regresi√≥n lineal el objetivo es utilizar los datos para trazar una l√≠nea que represente mejor la relaci√≥n entre dos variables.]

.pull-left[

.center[

### Ya que se puede trazar m√°s de una recta que razonablemente se ajuste a la distribuci√≥n de los datos, es preferible utilizar el m√©todo de los **m√≠nimos cuadrados** que resulta en una sola y mejor l√≠nea de regresi√≥n *.orange[(Recta del mejor ajuste)]*.
]
]

.pull-right[
<br>
.center[
<img src="https://media.giphy.com/media/W0R3W6eC7lkuOZYCYU/giphy.gif" width="70%"/>
]
]

> **M√≠nimos Cuadrados Ordinarios (MCO):** El objetivo de este procedimiento es estimar los par√°metros tal que la suma de cuadrados (SC) de las diferencias entre las observaciones (valores reales) y la l√≠nea recta estimada sea m√≠nima (Min SCError).



---

# MCO

Si lo que interesa es minimizar la suma de cuadrados del error...


.center[
### ¬øQu√© es el error?
]

--

.font1800[$$\hat{e}_i = y_i - \hat{y}_i$$]

### Entonces, interesa...


.pull-left[
.center[
<img src="img/Imagen7.jpg" width="90%"/>
]
]

.pull-right[

<br>
$$SCE = \sum_{i=1}^n (y_i - \hat{y}_i)^2$$
]

---

# MCO

### Minimizar SCE:

$$SCE = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^n (y_i - (\hat{\beta_0} + \hat{\beta_1}x_i))^2$$


$$Min SCE =  \frac{\partial SCE}{\partial \hat{\beta_j}}$$

--

### Ecuaciones normales:


$$\sum_{i=1}^n y_i = n \hat{\beta_0} + \hat{\beta_1} \sum_{i=1}^n x_i$$
$$\sum_{i=1}^n x_i y_i = \hat{\beta_0} \sum_{i=1}^n x_i + \hat{\beta_1} \sum_{i=1}^n x_i^2$$

---

# MCO


.font140[.orange[A partir de las ecuaciones normales se llega a:]]

<br>

$$\hat{\beta_0} = \bar{y} - \hat{\beta_1}\bar{x}$$

<br>
<br>


$$\begin{align}
\hat{\beta_1} & = & \frac{\sum_{i=1}^n x_i y_i - n \bar{x}\bar{y}}{\sum_{i=1}^n x_i^2 - n\bar{x}^2}   \nonumber \\
 & = & r \left( \frac{S_y}{S_x}\right)  \nonumber \\
 & = & \frac{cov(x,y)}{V(x)}
\end{align}$$



---


#MCO 

.font150[Una vez que se han determinado las estimaciones por MCO del intercepto y de la pendiente, se obtiene la l√≠nea de regresi√≥n de MCO.]

<br>

$$E(Y/X) = \hat{\beta_0} + \hat{\beta_1}{X}$$

$$\hat{Y} = \hat{\beta_0} + \hat{\beta_1}{X}$$

<br>
<br>

> - **El intercepto,** $\hat{\beta_0}$ es el valor predicho de Y cuando $X = 0$, aunque en algunos casos no tiene sentido hacer $X = 0$.

> - **La pendiente,** $\hat{\beta_1}$ es de primordial inter√©s, pues indica la cantidad en la que cambia $\hat{Y}$ cuando X se incrementa en una unidad.



---



# Coeficiente de determinaci√≥n


Coeficiente de determinaci√≥n $r^2$: Proporci√≥n de la variabilidad de $Y$ que es posible explicar a trav√©s del modelo planteado, es decir, por la variaci√≥n de la variable dependiente $X$:

<br>

$$R^2 = r^2 \quad , \quad 0\leq R^2 \leq 1$$
<br>

> - Su c√°lculo es f√°cil, es el coeficiente de correlaci√≥n al cuadrado.
> - Para interpretar mejor el coeficiente de determinaci√≥n se debe convertir a porcentaje.


<br>

### ¬øCon cu√°nta exactitud predice la ecuaci√≥n de regresi√≥n a la variable $Y$ mediante la variable $X$?

> Si fuera posible hacer predicciones **perfectas** entonces $R^2 = 100\%$, esto significa que la variable independiente explica o representa toda la variaci√≥n de la variable dependiente


---




# Tipos de modelos

.pull-left[

### Modelo: Lin-Lin

$$Y_i = \beta_0 + \beta_1 X_i + U_i$$

<br>

.orange[Interpretaci√≥n:]

$$\beta = \frac{dY_n}{dX_n}$$


> Cambio esperado en nivel de $Y_n$ cuando $X_n$ aumenta una unidad

]

.pull-right[

### Modelo: Log-Log

$$ln(Y_i) = \beta_0 + \beta_1 ln(X_i) + U_i$$
<br>

.orange[Interpretaci√≥n:]

$$\beta = \frac{X_n}{Y_n}\frac{dY_n}{dX_n}$$


> Cambio porcentual (en tanto por uno) esperado en $Y_n$ cuando $X_n$ aumenta un uno por ciento (en tanto por uno, ie, 0.01)



]


---

# Tipos de modelos

.pull-left[

### Modelo: Log-Lin

$$ln(Y_i) = \beta_0 + \beta_1 X_i + U_i$$

<br>

.orange[Interpretaci√≥n:]

$$\beta = \frac{1}{Y_n}\frac{dY_n}{dX_n}$$


> Cambio porcentual (en tanto por uno) esperado en $Y_n$ cuando $X_n$ aumenta una unidad

]

.pull-right[

### Modelo: Lin-Log

$$Y_i = \beta_0 + \beta_1 ln(X_i) + U_i$$
<br>

.orange[Interpretaci√≥n:]

$$\beta = X_n\frac{dY_n}{dX_n}$$


> Cambio esperado en el nivel de $Y_n$ cuando $X_n$ aumenta un uno por ciento (en tanto por uno)



]

---


# Ejercicios en clase: .orange[Estimar]

.pull-left[

----

```{c1, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE}


library(wooldridge)
library(tidyverse)


data("ceosal1")


modelo1 <- lm(salary ~ roe, ceosal1)

summary(modelo1)



```


----

.center[
.font160[.green[**2).**]] **¬øC√≥mo se interpreta esta ecuaci√≥n?**
]

.orange[$$\hat{salary} = 963,19 + 18,501 roe$$]


- Primero, si el rendimiento sobre el capital es cero, $roe = 0$, entonces el sueldo que se predice corresponde al intercepto, 963.191, es decir, $963,191, dado que salary se mide en miles.

]


.pull-right[

.font70[
```{r, warning=FALSE, message=FALSE, eval=TRUE}

library(wooldridge)
library(tidyverse)

data("ceosal1")

modelo1 <- lm(salary ~ roe, ceosal1)

summary(modelo1)

```
]

- Luego, el cambio que se predice para el sueldo en funci√≥n del cambio en el roe se expresa como: 

$$\vartriangle \hat{salary} = 18,501 (\vartriangle roe)$$

Esto significa que cuando el rendimiento sobre capital aumente en un punto porcentual, $roe = 1$, se predice que el sueldo variar√° aproximadamente 18.5, es decir $18,500.

]


---

# Ejercicios en clase: .orange[Estimar]

.pull-left[

<br>
<br>
<br>

<img src="img/roe1.jpg" width="100%"/>

]


.pull-right[

### La estimaci√≥n tambi√©n la puedo utilizar para comparar los sueldos que se predicen para diferentes valores del *roe*.

> Suponga que $roe = 30$


.orange[$$\hat{salary} = 963,19 + 18,501 (30) =  1,518,221$$]


> Un poco m√°s de $1.5 millones

Esto no significa que si un CEO est√° en una empresa con $roe = 30$, implique que gane  $ 1,518,221

.center[**Hay otros factores que afectan el sueldo!!**]

.green[**Esto solo es una PREDICCI√ìN**] a partir de la l√≠nea de regresi√≥n.

]


---

# Ejercicios en clase: .orange[Estimar]



<br>
<br>


> .font160[.green[**3).**]]  Utilice la base de datos `WAGE1` y estime un modelo para la poblaci√≥n de personas en la fuerza de trabajo en 1976, en d√≥nde, utilice como variable respuesta o end√≥gena `wage`, y predictora o ex√≥gena `educ`.


<br>
<br>
<br>

> .font160[.green[**4).**]] Interprete el $R^2$ para las dos estimaciones anteriores. ¬øQu√© ocurre?

<br>
<br>
<br>


> .font160[.green[**5).**]] ¬øQu√© forma funcional se ajusta mejor en t√©rminos de interpretabilidad en los dos modelos anteriores? Explique.



---


name: intervalos
class: inverse, center, middle

# `r icon("dice-d6")`
# Estimaci√≥n por intervalos
----

.right[
.bottom[
####  [`r icon("bell")`](#menu)
]
]



---


# Estimaci√≥n por Intervalos: Algunas Ideas B√°sicas


Si se cumplen los supuestos del modelo de regresi√≥n lineal, entonces la distribuci√≥n del estimador de MCO es normal y se puede utilizar para construir intervalos de confianza y hacer pruebas de hip√≥tesis.

<br>
<br>

----

.center[

### Intervalos de Confianza para los Coeficientes

Un intervalo de confianza para un coeficiente $\beta_j$ es un rango de valores dentro del cual se espera que est√© el verdadero valor del coeficiente con una cierta probabilidad.

]


----

---


# Intervalos de confianza para los coeficientes de regresi√≥n $\beta_0$ y $\beta_1$


.pull-left[

Un intervalo de confianza del $(1-\alpha)100%$ para el coeficiente de regresi√≥n $\beta_1$ est√° dado por:

$$\hat{\beta}_1 \pm t_{\alpha/2, n-2} \frac{\hat{\sigma}}{\sqrt{\sum_{i=1}^{n}(x_{i1}-\bar{x}_1)^2}}$$

El intervalo de confianza para el coeficiente de regresi√≥n $\beta_0$ es:

$$\hat{\beta}_0\pm t_{\alpha/2,n-2}\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\sum_{i=1}^{n}(x_i-\bar{x})^2}}$$

]

.pull-right[

En ambos casos, $t_{\alpha/2,n-2}$ es el valor cr√≠tico de la distribuci√≥n $t$ de Student con $n-2$ grados de libertad y un nivel de significancia $\alpha$.

La estimaci√≥n del error est√°ndar $\hat{\sigma}$ se calcula como:

$$\hat{\sigma}=\sqrt{CME}=\sqrt{\frac{\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}{n-2}}$$

El intervalo de confianza nos indica que con un nivel de confianza de $1-\alpha$, el verdadero valor del coeficiente de regresi√≥n est√° contenido en el intervalo de confianza calculado.

]

.orange[**Nota:** Recuerda que] $t_{\alpha/2, n-2}$ .orange[es el valor cr√≠tico de la distribuci√≥n] $t$ .orange[de Student con] $n-2$ .orange[grados de libertad, que deja una probabilidad de] $\alpha/2$ .orange[en la cola superior y] $\alpha/2$ .orange[en la cola inferior.]



---

# En R...

.pull-left[


Siendo `residuos` el objeto que guarde los residuos del modelo estimado

```{c1, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE}


# C√°lculo de s (estimaci√≥n de la desviaci√≥n est√°ndar del error)
s <- sqrt(sum(residuos^2) / (n - 2))

# C√°lculo de la matriz de varianzas y covarianzas de los coeficientes
X <- model.matrix(modelo)
V <- s^2 * solve(t(X) %*% X)

# C√°lculo de los errores est√°ndar de los coeficientes
se_beta_0 <- sqrt(V[1, 1])
se_beta_1 <- sqrt(V[2, 2])

```

]

.pull-right[

En particular, vamos a ajustar un modelo de regresi√≥n lineal simple utilizando la variable horsepower (caballos de fuerza) como predictor de la variable mpg (millas por gal√≥n).

```{c1, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE}

data(mtcars)
  
model <- lm(mpg ~ horsepower, data = mtcars)
  
confint(model)

  
# Esta es la salida

                   2.5 %      97.5 %
(Intercept) 28.90595959 39.18122022
horsepower  -0.15243840 -0.07949478
```

]





---

class: middle, center


# ¬øDistribuci√≥n t-student o normal?


---

# ¬øDistribuci√≥n t-student o normal?

La raz√≥n por la que se utiliza la distribuci√≥n t en lugar de la distribuci√≥n normal se debe a que la distribuci√≥n t tiene colas m√°s anchas que la distribuci√≥n normal, lo que implica que para muestras peque√±as o cuando la varianza del error es desconocida, el intervalo de confianza basado en la distribuci√≥n t es m√°s amplio que el intervalo basado en la distribuci√≥n normal. Esto se hace para tener una mayor probabilidad de incluir el verdadero valor del par√°metro desconocido, lo que es especialmente importante en muestras peque√±as.

<br>

----
> .green[Cuando el tama√±o de la muestra es grande y la varianza del error es conocida, la distribuci√≥n t y la distribuci√≥n normal son muy similares y la diferencia en la amplitud del intervalo de confianza basado en ambas distribuciones es despreciable. Por lo tanto, en ese caso se puede utilizar la distribuci√≥n normal.]

----


.center[
## Pero... y entonces?
]

---

# ¬øDistribuci√≥n t-student o normal?

Es cierto que cuando se estima una regresi√≥n lineal en R, se calculan los valores t de los estimadores de los coeficientes de la regresi√≥n, incluso cuando el tama√±o de la muestra es grande. Esto se debe a que, en general, es preferible utilizar la distribuci√≥n t para realizar pruebas de hip√≥tesis y construir intervalos de confianza, ya que esta distribuci√≥n tiene en cuenta la incertidumbre adicional que se presenta al estimar la desviaci√≥n est√°ndar del error de la regresi√≥n a partir de los datos.


<br>


.pull-left[

.orange[Adem√°s, aunque la diferencia en la amplitud del intervalo de confianza entre la distribuci√≥n t y la distribuci√≥n normal puede ser despreciable para muestras grandes, la distribuci√≥n t se utiliza com√∫nmente para mantener la consistencia en el enfoque estad√≠stico, es decir, utilizar la misma distribuci√≥n en todos los casos, independientemente del tama√±o de la muestra o la estimaci√≥n de la desviaci√≥n est√°ndar del error.]
]

.pull-right[


<img src="https://media.giphy.com/media/FcuiZUneg1YRAu1lH2/giphy.gif" width="60%">


]

---


class: middle, center

# En resumen...

<br>

En resumen, aunque en la pr√°ctica el uso de la distribuci√≥n t puede no tener un gran impacto en los resultados cuando la muestra es grande, es una pr√°ctica com√∫n en estad√≠stica para mantener la consistencia en la aplicaci√≥n de los m√©todos estad√≠sticos.


---






# Pruebas de hip√≥tesis: m√©todo del intervalo de confianza


* Hasta ahora, hemos estimado los coeficientes del modelo y hemos construido intervalos de confianza para ellos.

* Pero a veces, queremos hacer una afirmaci√≥n m√°s espec√≠fica sobre el valor de un coeficiente en particular.

* Es aqu√≠ donde entran las pruebas de hip√≥tesis.

## Hip√≥tesis nula y alternativa

Las pruebas de hip√≥tesis implican dos hip√≥tesis:

> * Hip√≥tesis nula. $H_0$: afirmaci√≥n sobre el valor de un par√°metro poblacional
> * Hip√≥tesis alternativa. $H_1$: afirmaci√≥n que contradice $H_0$

.orange[**Ejemplo:**]

$H_0$: $\beta_1 = 0$ (no hay relaci√≥n entre X e Y) 

$H_1$: $\beta_1 \neq 0$ (hay una relaci√≥n entre X e Y)

---

## Estad√≠stico de prueba

Un estad√≠stico de prueba es una funci√≥n de los datos de la muestra que se utiliza para probar la hip√≥tesis nula.

En el modelo lineal simple, el estad√≠stico de prueba para probar la hip√≥tesis nula:


$H_0: \beta_1 = \beta_{HipNula}$ es: 


$$t = \frac{\hat{\beta}_1 - \beta_{HipNula}}{ee(\hat{\beta}_1)}$$

donde,

* $\hat{\beta}_1$ es el estimador de m√°xima verosimilitud de $\beta_1$

* $ee(\hat{\beta}_1)$ es el error est√°ndar de $\hat{\beta}1$

* $\beta_{HipNula}$ es el valor especificado en la hip√≥tesis nula

---

## Regi√≥n cr√≠tica


Para tomar una decisi√≥n sobre si rechazar o no la hip√≥tesis nula, necesitamos establecer una regi√≥n cr√≠tica

----

> La regi√≥n cr√≠tica es un conjunto de valores para el estad√≠stico de prueba en el que rechazamos la hip√≥tesis nula

----


.pull-left[

.orange[**En el caso de una prueba bilateral, la regi√≥n cr√≠tica est√° dada por:**]

$$|t| > t_{n-2, \frac{\alpha}{2}}$$

donde $t_{n-2, \frac{\alpha}{2}}$ es el valor cr√≠tico de la distribuci√≥n t de Student con $n-2$ grados de libertad y un nivel de significancia $\alpha/2$


]

.pull-right[

```{r, warning=FALSE, message=FALSE, eval=TRUE, fig.height=4}

# Generar datos
x <- seq(-4, 4, 0.01)
y <- dt(x, df = 10)

# Intervalo de confianza
conf_int <- qt(c(0.025, 0.975), df = 10)

# Crear gr√°fico en ggplot
ggplot(data.frame(x = x, y = y), aes(x = x, y = y)) + 
  geom_line(color = "blue", size = 1) +
  geom_vline(xintercept = conf_int[1], linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = conf_int[2], linetype = "dashed", color = "red", size = 1) +
  theme_bw()

```


]


---

.pull-left[

## Valor p

En lugar de establecer una regi√≥n cr√≠tica, podemos utilizar el valor p para tomar una decisi√≥n.

El valor p es la probabilidad de obtener un valor del estad√≠stico de prueba tan extremo o m√°s extremo que el valor observado, asumiendo que la hip√≥tesis nula es verdadera.

Si el valor p es menor que el nivel de significancia $\alpha$, rechazamos la hip√≥tesis nula

## Regla $2t$

Si el n√∫mero de grados de libertad es 20 o m√°s, y si $\alpha$, el nivel de significancia, se fija en 0.05, se rechaza la hip√≥tesis nula $\beta_1 = 0$ si el valor de $t = \hat{\beta_1}/ee(\hat{\beta_1})$ es superior a 2 en valor absoluto.

]

.pull-right[

## Resumen


.orange[La prueba del intervalo de confianza se realiza de la siguiente manera:]

Estimamos el intervalo de confianza al nivel de significancia $\alpha$ para $\beta_1$ usando la f√≥rmula ya vista.

Si el intervalo de confianza no contiene el valor 0, entonces rechazamos la hip√≥tesis nula y concluimos que hay evidencia estad√≠stica para afirmar que $\beta_1$ es diferente de cero al nivel de significancia $\alpha$. En caso contrario, no podemos rechazar la hip√≥tesis nula.

----

El p-value para la prueba de hip√≥tesis es el valor de la probabilidad acumulada en la cola correspondiente de la distribuci√≥n t con $n-2$ grados de libertad, utilizando la estad√≠stica de prueba $t = \frac{\hat{\beta_1}}{ee(\hat{\beta_1})}$. Si la p-value es menor que el nivel de significancia $\alpha$, entonces rechazamos la hip√≥tesis nula.


]

---

# En R...

Supongamos que tenemos un modelo de regresi√≥n lineal simple con una variable explicativa $x$ y una variable respuesta $y$. Queremos probar las siguientes hip√≥tesis sobre los coeficientes de regresi√≥n:

<br>

> $H_0: \beta_1 = 0$ (la variable explicativa no tiene efecto sobre la variable respuesta)

> $H_1: \beta_1 \neq 0$ (la variable explicativa s√≠ tiene efecto sobre la variable respuesta)

<br>

Podemos realizar la prueba de hip√≥tesis utilizando la funci√≥n `summary()` en R despu√©s de ajustar el modelo de regresi√≥n lineal simple. 

> La funci√≥n `summary()` proporciona informaci√≥n sobre el modelo, incluyendo el valor del estad√≠stico de prueba, el valor $p$ y el intervalo de confianza para los coeficientes de regresi√≥n.

---

# En R...

Por ejemplo, utilizando el conjunto de datos mtcars, podemos ajustar el siguiente modelo:



.pull-left[

`model <- lm(mpg ~ wt, data = mtcars)` 

`summary(model)`

.font70[
```{r, warning=FALSE, message=FALSE, eval=TRUE}

model <- lm(mpg ~ wt, data = mtcars)
summary(model)

```
]

]

.pull-right[

* En la tabla de coeficientes, podemos ver que el coeficiente estimado para wt es -5.3445 con un error est√°ndar de 0.5591. 

* Podemos probar las hip√≥tesis utilizando la prueba $t$ sobre el coeficiente de regresi√≥n para wt. La estad√≠stica de prueba es $t = \frac{-5.3445}{0.5591} = -9.559$ y el valor $p$ es 1.29e-10. 

* Dado que el valor $p$ es menor que cualquier nivel de significancia com√∫n, podemos rechazar la hip√≥tesis nula y concluir que hay evidencia suficiente para afirmar que la variable wt tiene un efecto significativo en mpg.

]



---




# Predicci√≥n

.pull-left[



* En muchas situaciones, nos interesa predecir el valor de una variable dependiente $Y$ para un conjunto de valores dados de las variables explicativas $X_1, X_2, ..., X_k$.

* Por ejemplo, podemos querer predecir la demanda de un producto en funci√≥n de su precio y otros factores relacionados.

* El an√°lisis de regresi√≥n nos permite modelar la relaci√≥n entre las variables explicativas y la variable dependiente, y usar ese modelo para hacer predicciones.

]


.pull-right[


<img src="https://media.giphy.com/media/3otPot5ichOK0OWk3C/giphy.gif" width="90%">


]

---

# Predicci√≥n

Una vez que se han estimado los par√°metros del modelo de regresi√≥n lineal simple, podemos usar el modelo para hacer predicciones.

----

La predicci√≥n puntual de $Y$ para un valor dado de $X$ es: 

$$\hat{Y} = \hat{\beta_0} + \hat{\beta_1} X$$

----


Donde $\hat{\beta_0}$ y $\hat{\beta_1}$ son las estimaciones de los par√°metros $\beta_0$ y $\beta_1$ obtenidas a partir de los datos.

.orange[Es importante tener en cuenta que la predicci√≥n puntual solo es exacta si el modelo es v√°lido y los errores son normales e independientes.]


---

# Predicci√≥n

## Intervalo de confianza para la predicci√≥n

Un intervalo de confianza para una nueva observaci√≥n de $Y$ en el punto $X_0$ est√° dado por:

$$\hat{Y}_0 \pm t_{\alpha/2,n-2} \cdot \hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x_0-\bar{x})^2}{\sum_{i=1}^n (x_i - \bar{x})^2}}$$


Donde:

$\hat{Y}_0$ es la predicci√≥n puntual de $Y$ en $X_0$.

$t_{\alpha/2,n-2}$ es el valor cr√≠tico de $t$ con $(n-2)$ grados de libertad y un nivel de confianza $(1-\alpha)$.

$n$ es el tama√±o de la muestra.

$\bar{X}$ es la media de las observaciones de $X$.

El intervalo de confianza nos indica el rango de valores en el que podemos esperar que caiga una nueva observaci√≥n de $Y$ con una probabilidad $(1-\alpha)$.

---

# Predicci√≥n

## Intervalo de confianza para la predicci√≥n

Un intervalo de confianza para una nueva observaci√≥n de $Y$ en el punto $X_0$ est√° dado por:

$$\hat{Y}_0 \pm t_{\alpha/2,n-2} \cdot \hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x_0-\bar{x})^2}{\sum_{i=1}^n (x_i - \bar{x})^2}}$$


.orange[**Intervalo de predicci√≥n:**] Se utiliza cuando la ecuaci√≥n de regresi√≥n se emplea para predecir una Y individual para un valor de X dado.


.orange[**Ejemplo:**] Estimar el salario de un ejecutivo minorista en particular con
20 a√±os de experiencia.


---

# Predicci√≥n

## Intervalo de confianza para la media

Un intervalo de confianza para la media de $Y$ est√° dado por:

$$\hat{Y}_0 \pm t_{\alpha/2,n-2} \cdot \hat{\sigma} \sqrt{\frac{1}{n} + \frac{(x_0-\bar{x})^2}{\sum_{i=1}^n (x_i - \bar{x})^2}}$$


.orange[**Intervalo de predicci√≥n media:**] Se utiliza cuando la ecuaci√≥n de regresi√≥n se emplea para predecir el valor medio de Y para una X dada.


.orange[**Ejemplo:**] Se puede usar un intervalo de confianza para estimar el salario
medio de todos los ejecutivos en la industria minorista con base en sus a√±os de experiencia.



---


# En R...


.pull-left[

.scroll-box-20[

.font70[

```{r, eval=FALSE,echo=TRUE}
# Cargar la base de datos mtcars
data(mtcars)

# Ajustar el modelo de regresi√≥n lineal simple
model <- lm(mpg ~ wt, data = mtcars)

# Crear un conjunto de valores de wt para la predicci√≥n
newdata <- data.frame(wt = seq(from = min(mtcars$wt), to = max(mtcars$wt), length.out = 100))

# Calcular la predicci√≥n y el intervalo de confianza para la predicci√≥n
pred <- predict(model, newdata = newdata, interval = "prediction", level = 0.95)

# Calcular la predicci√≥n media y el intervalo de confianza para la predicci√≥n media
pred_mean <- predict(model, newdata = newdata, interval = "confidence", level = 0.95)

# Graficar los resultados
plot(mtcars$wt, mtcars$mpg, pch = 16, xlab = "Weight", ylab = "Miles per gallon")
lines(newdata$wt, pred[, 1], lwd = 2, col = "blue")
lines(newdata$wt, pred[, 2], lwd = 2, col = "red", lty = 2)
lines(newdata$wt, pred[, 3], lwd = 2, col = "red", lty = 2)
lines(newdata$wt, pred_mean[, 1], lwd = 2, col = "green")
lines(newdata$wt, pred_mean[, 2], lwd = 2, col = "orange", lty = 2)
lines(newdata$wt, pred_mean[, 3], lwd = 2, col = "orange", lty = 2)
legend("topright", legend = c("Predicci√≥n", "Intervalo de confianza para la predicci√≥n",
                              "Predicci√≥n media", "Intervalo de confianza para la predicci√≥n media"),
       lty = c(1, 2, 1, 2), col = c("blue", "red", "green", "orange"), bty = "n", cex = 0.8)

```

]
]
]


.pull-right[


```{r, echo=FALSE}
# Cargar la base de datos mtcars
data(mtcars)

# Ajustar el modelo de regresi√≥n lineal simple
model <- lm(mpg ~ wt, data = mtcars)

# Crear un conjunto de valores de wt para la predicci√≥n
newdata <- data.frame(wt = seq(from = min(mtcars$wt), to = max(mtcars$wt), length.out = 100))

# Calcular la predicci√≥n y el intervalo de confianza para la predicci√≥n
pred <- predict(model, newdata = newdata, interval = "prediction", level = 0.95)

# Calcular la predicci√≥n media y el intervalo de confianza para la predicci√≥n media
pred_mean <- predict(model, newdata = newdata, interval = "confidence", level = 0.95)

# Graficar los resultados
plot(mtcars$wt, mtcars$mpg, pch = 16, xlab = "Weight", ylab = "Miles per gallon")
lines(newdata$wt, pred[, 1], lwd = 2, col = "blue")
lines(newdata$wt, pred[, 2], lwd = 2, col = "red", lty = 2)
lines(newdata$wt, pred[, 3], lwd = 2, col = "red", lty = 2)
lines(newdata$wt, pred_mean[, 1], lwd = 2, col = "green")
lines(newdata$wt, pred_mean[, 2], lwd = 2, col = "orange", lty = 2)
lines(newdata$wt, pred_mean[, 3], lwd = 2, col = "orange", lty = 2)
legend("topright", legend = c("Predicci√≥n", "Intervalo de confianza para la predicci√≥n",
                              "Predicci√≥n media", "Intervalo de confianza para la predicci√≥n media"),
       lty = c(1, 2, 1, 2), col = c("blue", "red", "green", "orange"), bty = "n", cex = 0.8)

```

]

---

# En R...

En este ejemplo, ajustamos un modelo de regresi√≥n lineal simple que predice el consumo de gasolina `(mpg)` a partir del peso del autom√≥vil `(wt)` utilizando la base de datos mtcars. Luego creamos un conjunto de valores de wt para la predicci√≥n.


> .orange[**Para calcular el intervalo de confianza para la predicci√≥n,**] utilizamos la funci√≥n `predict()` con el argumento `interval = "prediction"` y especificamos el nivel de confianza deseado con el argumento `level = 0.95`. Esto nos da tres columnas en la salida: la predicci√≥n puntual, el l√≠mite inferior del intervalo de confianza y el l√≠mite superior del intervalo de confianza.

----

> .orange[**Para calcular el intervalo de confianza para la predicci√≥n media,**] utilizamos la funci√≥n `predict()` con el argumento `interval = "confidence"` y especificamos el nivel de confianza deseado con el argumento `level = 0.95`. Esto nos da tres columnas en la salida: la predicci√≥n puntual.



---



# Diagn√≥stico y evaluaci√≥n del modelo

- La evaluaci√≥n del modelo incluye la comprobaci√≥n de las suposiciones de los residuos.

- Si los residuos no siguen una distribuci√≥n normal o si hay patrones en los residuos, entonces es posible que el modelo no sea apropiado para realizar inferencias.

- Tambi√©n se pueden utilizar medidas como $R^2$ o el error cuadr√°tico medio para evaluar la calidad del ajuste del modelo.

### En General,


- La forma matricial del modelo lineal m√∫ltiple es una herramienta poderosa para el an√°lisis y la resoluci√≥n de problemas de regresi√≥n.

- La interpretaci√≥n de los coeficientes permite entender la relaci√≥n entre las variables.

- La evaluaci√≥n del modelo es esencial para verificar su validez y utilidad en la toma de decisiones.



---

# ANOVA


```{r, echo=FALSE, results='asis'}
cat("
<table>
  <caption>Tabla ANOVA para el modelo de regresi√≥n lineal m√∫ltiple</caption>
  <thead>
    <tr>
      <th> Fuente de variaci√≥n </th>
      <th> Suma de cuadrados </th>
      <th> Grados de libertad </th>
      <th> Cuadrado medio </th>
      <th> F </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td> Regresi√≥n </td>
      <td> $SS_R$ </td>
      <td> $p$ </td>
      <td> $MS_R=SS_R/p$ </td>
      <td> $F=\\frac{MS_R}{MS_E}$ </td>
    </tr>
    <tr>
      <td> Error </td>
      <td> $SS_E$ </td>
      <td> $n-p-1$ </td>
      <td> $MS_E=SS_E/(n-p-1)$ </td>
      <td> </td>
    </tr>
    <tr>
      <td> Total </td>
      <td> $SS_T$ </td>
      <td> $n-1$ </td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>
")

```

Para conocer la variabilidad que explica cada uno de los predictores incorporadas en el modelo se recurre a un ANOVA, ya que es el m√©todo que se encarga de analizar la varianza.

Tal y como ocurre en los modelos lineales simples o en los estudios de correlaci√≥n, por muy alta que sea la bondad de ajuste, si el test F no resulta significativo no se puede aceptar el modelo como v√°lido puesto que no es capaz de explicar la varianza observada mejor de lo esperado por azar.



---

# Ejemplo

Un estudio quiere generar un modelo que permita predecir la esperanza de vida media de los habitantes de una ciudad en funci√≥n de diferentes variables. Se dispone de informaci√≥n sobre: habitantes, analfabetismo, ingresos, esperanza de vida, asesinatos, universitarios, heladas, √°rea y densidad poblacional.


```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE}

# El data set empleado es el state.x77
# Para facilitar su interpretaci√≥n se renombra y se modifica
library(dplyr)
datos <- as.data.frame(state.x77)
datos <- rename(habitantes = Population, analfabetismo = Illiteracy,
                ingresos = Income, esp_vida = `Life Exp`, asesinatos = Murder,
                universitarios = `HS Grad`, heladas = Frost, area = Area,
                .data = datos)
datos <- mutate(.data = datos, densidad_pobl = habitantes * 1000 / area)

```


---

# 1. Analizar la relaci√≥n entre variables

El primer paso a la hora de establecer un modelo lineal m√∫ltiple es estudiar la relaci√≥n que existe entre variables. Esta informaci√≥n es cr√≠tica a la hora de identificar cu√°les pueden ser los mejores predictores para el modelo, qu√© variables presentan relaciones de tipo no lineal (por lo que no pueden ser incluidas) y para identificar colinialidad entre predictores. A modo complementario, es recomendable representar la distribuci√≥n de cada variable mediante histogramas.

Las dos formas principales de hacerlo son mediante representaciones gr√°ficas (gr√°ficos de dispersi√≥n) y el c√°lculo del coeficiente de correlaci√≥n de cada par de variables.


```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE, fig.height=3}
round(cor(x = datos, method = "pearson"), 3)
```


---

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE, fig.height=4}
library(GGally)
ggpairs(datos, lower = list(continuous = "smooth"),
        diag = list(continuous = "barDiag"), axisLabels = "none")
```

---

# 1. Analizar la relaci√≥n entre variables

Del an√°lisis preliminar se pueden extraer las siguientes conclusiones:

----

* Las variables que tienen una mayor relaci√≥n lineal con la esperanza de vida son: asesinatos (r= -0.78), analfabetismo (r= -0.59) y universitarios (r= 0.58).

----

* Asesinatos y analfabetismo est√°n medianamente correlacionados (r = 0.7) por lo que posiblemente no sea √∫til introducir ambos predictores en el modelo.

----

* Las variables habitantes, √°rea y densidad poblacional muestran una distribuci√≥n exponencial, una transformaci√≥n logar√≠tmica posiblemente har√≠a m√°s normal su distribuci√≥n.



---

# 2. Generar el modelo

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE, fig.height=4}
modelo <- lm(esp_vida ~ habitantes + ingresos + analfabetismo + asesinatos +
               universitarios + heladas + area + densidad_pobl, data = datos )
summary(modelo)
```

---

# 2. Generar el modelo

### El modelo con todas las variables introducidas como predictores tiene un R2 alta (0.7013), es capaz de explicar el 70% de la variabilidad observada en la esperanza de vida. 

### El p-value del modelo es significativo (3.787e-10) por lo que se puede aceptar que el modelo no es por azar, al menos uno de los coeficientes parciales de regresi√≥n es distinto de 0. Muchos de ellos no son significativos, lo que es un indicativo de que podr√≠an no contribuir al modelo.

---

# Selecci√≥n de los predictores

A la hora de seleccionar los predictores que deben formar parte del modelo se pueden seguir varios m√©todos:

- **M√©todo jer√°rquico:** bas√°ndose en el criterio del analista, se introducen unos predictores determinados en un orden determinado.

- **M√©todo de entrada forzada:** se introducen todos los predictores simult√°neamente.

- **M√©todo paso a paso (stepwise):** emplea criterios matem√°ticos para decidir qu√© predictores contribuyen significativamente al modelo y en qu√© orden se introducen. Dentro de este m√©todo se diferencias tres estrategias:


---

# Selecci√≥n de los predictores

> **M√©todo paso a paso (stepwise):** 


**Direcci√≥n forward:** El modelo inicial no contiene ning√∫n predictor, solo el par√°metro $\beta_0$
. A partir de este se generan todos los posibles modelos introduciendo una sola variable de entre las disponibles. 


Aquella variable que mejore en mayor medida el modelo se selecciona. A continuaci√≥n se intenta incrementar el modelo probando a introducir una a una las variables restantes. Si introduciendo alguna de ellas mejora, tambi√©n se selecciona. En el caso de que varias lo hagan, se selecciona la que incremente en mayor medida la capacidad del modelo. 


Este proceso se repite hasta llegar al punto en el que ninguna de las variables que quedan por incorporar mejore el modelo.


---

# Selecci√≥n de los predictores

**Direcci√≥n backward:** El modelo se inicia con todas las variables disponibles incluidas como predictores. Se prueba a eliminar una a una cada variable, si se mejora el modelo, queda excluida. 

Este m√©todo permite evaluar cada variable en presencia de las otras.


---

# Selecci√≥n de los predictores

**Doble o mixto:** Se trata de una combinaci√≥n de la selecci√≥n forward y backward. Se inicia igual que el forward pero tras cada nueva incorporaci√≥n se realiza un test de extracci√≥n de predictores no √∫tiles como en el backward. Presenta la ventaja de que si a medida que se a√±aden predictores, alguno de los ya presentes deja de contribuir al modelo, se elimina.


---

# Selecci√≥n de los predictores


El m√©todo paso a paso requiere de alg√∫n criterio matem√°tico para determinar si el modelo mejora o empeora con cada incorporaci√≥n o extracci√≥n. Existen varios par√°metros empelados, de entre los que destacan el Cp, AIC, BIC y R2 ajustado, cada uno de ellos con ventajas e inconvenientes. 

> El m√©todo Akaike(AIC) tiende a ser m√°s restrictivo e introducir menos predictores que el R2-ajustado. Para un mismo set de datos, no todos los m√©todos tienen porque concluir en un mismo modelo.


---

# Selecci√≥n de los predictores


.pull-left[
Es frecuente encontrar ejemplos en los que la selecci√≥n de predictores se basa en el p-value asociado a cada uno. Si bien este m√©todo es sencillo e intuitivo, presenta m√∫ltiples problemas: la inflaci√≥n del error tipo I debida a las comparaciones m√∫ltiples, la eliminaci√≥n de los predictores menos significativos tiende a incrementar la significancia de los otros predictores ‚Ä¶ Por esta raz√≥n, a excepci√≥n de casos muy sencillos con pocos predictores, es preferible no emplear los p-values como criterio de selecci√≥n.
]

.pull-right[

.center[
# ¬ø¬ø P-Value ??
]
]



---

# Selecci√≥n de los predictores

.pull-left[
En el caso de variables categ√≥ricas, si al menos uno de sus niveles es significativo, se considera que la variable lo es. Cabe mencionar que, si una variable se excluye del modelo como predictor, significa que no aporta informaci√≥n adicional al modelo, pero s√≠ puede estar relacionada con la variable respuesta.

En R la funci√≥n step() permite encontrar el mejor modelo basado en AIC utilizando cualquiera de las 3 variantes del m√©todo paso a paso.

]


.center[
# Variables categ√≥ricas
]
]


---

# 3. Selecci√≥n de los mejores predictores

En este caso se van a emplear la estrategia de stepwise mixto. El valor matem√°tico empleado para determinar la calidad del modelo va a ser Akaike (AIC).

```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE, fig.height=4}
step(object = modelo, direction = "both", trace = 1)
```


El mejor modelo resultante del proceso de selecci√≥n ha sido:

```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE, fig.height=4}
modelo <- (lm(formula = esp_vida ~ habitantes + asesinatos + universitarios +
              heladas, data = datos))
summary(modelo)
```

---

# 4. Intervalos de confianza

Es recomendable mostrar el intervalo de confianza para cada uno de los coeficientes parciales de regresi√≥n:

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE, fig.height=4}

confint(lm(formula = esp_vida ~ habitantes + asesinatos + universitarios +
            heladas, data = datos))

```

---

# 5. Validaci√≥n de condiciones para la regresi√≥n m√∫ltiple lineal

> Relaci√≥n lineal entre los predictores num√©ricos y la variable respuesta:


Esta condici√≥n se puede validar bien mediante diagramas de dispersi√≥n entre la variable dependiente y cada uno de los predictores (como se ha hecho en el an√°lisis preliminar) o con diagramas de dispersi√≥n entre cada uno de los predictores y los residuos del modelo. Si la relaci√≥n es lineal, los residuos deben de distribuirse aleatoriamente en torno a 0 con una variabilidad constante a lo largo del eje X. Esta √∫ltima opci√≥n suele ser m√°s indicada ya que permite identificar posibles datos at√≠picos.



```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE, fig.height=4}

library(ggplot2)
library(gridExtra)
plot1 <- ggplot(data = datos, aes(habitantes, modelo$residuals)) +
    geom_point() + geom_smooth(color = "firebrick") + geom_hline(yintercept = 0) +
    theme_bw()
plot2 <- ggplot(data = datos, aes(asesinatos, modelo$residuals)) +
    geom_point() + geom_smooth(color = "firebrick") + geom_hline(yintercept = 0) +
    theme_bw()
plot3 <- ggplot(data = datos, aes(universitarios, modelo$residuals)) +
    geom_point() + geom_smooth(color = "firebrick") + geom_hline(yintercept = 0) +
    theme_bw()
plot4 <- ggplot(data = datos, aes(heladas, modelo$residuals)) +
    geom_point() + geom_smooth(color = "firebrick") + geom_hline(yintercept = 0) +
    theme_bw()
grid.arrange(plot1, plot2, plot3, plot4)

```

---

Se cumple la linealidad para todos los predictores

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=FALSE, fig.height=4}

library(ggplot2)
library(gridExtra)
plot1 <- ggplot(data = datos, aes(habitantes, modelo$residuals)) +
    geom_point() + geom_smooth(color = "firebrick") + geom_hline(yintercept = 0) +
    theme_bw()
plot2 <- ggplot(data = datos, aes(asesinatos, modelo$residuals)) +
    geom_point() + geom_smooth(color = "firebrick") + geom_hline(yintercept = 0) +
    theme_bw()
plot3 <- ggplot(data = datos, aes(universitarios, modelo$residuals)) +
    geom_point() + geom_smooth(color = "firebrick") + geom_hline(yintercept = 0) +
    theme_bw()
plot4 <- ggplot(data = datos, aes(heladas, modelo$residuals)) +
    geom_point() + geom_smooth(color = "firebrick") + geom_hline(yintercept = 0) +
    theme_bw()
grid.arrange(plot1, plot2, plot3, plot4)

```


---

> Distribuci√≥n normal de los residuos:

Tanto el an√°lisis gr√°fico como es test de hip√≥tesis confirman la normalidad.

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE, fig.height=2}

qqnorm(modelo$residuals)
qqline(modelo$residuals)

shapiro.test(modelo$residuals)

```


---

> Variabilidad constante de los residuos (homocedasticidad):


.pull-left[

Al representar los residuos frente a los valores ajustados por el modelo, los primeros se tienen que distribuir de forma aleatoria en torno a cero, manteniendo aproximadamente la misma variabilidad a lo largo del eje X. Si se observa alg√∫n patr√≥n espec√≠fico, por ejemplo forma c√≥nica o mayor dispersi√≥n en los extremos, significa que la variabilidad es dependiente del valor ajustado y por lo tanto no hay homocedasticidad.

]


.pull-right[

```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE, fig.height=2}

ggplot(data = datos, aes(modelo$fitted.values, modelo$residuals)) +
geom_point() +
geom_smooth(color = "firebrick", se = FALSE) +
geom_hline(yintercept = 0) +
theme_bw()


library(lmtest)
bptest(modelo)

```


]


---

> Variabilidad constante de los residuos (homocedasticidad):

No hay evidencias de falta de homocedasticidad.

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=FALSE, fig.height=2}

ggplot(data = datos, aes(modelo$fitted.values, modelo$residuals)) +
geom_point() +
geom_smooth(color = "firebrick", se = FALSE) +
geom_hline(yintercept = 0) +
theme_bw()

library(lmtest)
bptest(modelo)


```


---


# Anova


En este ejemplo se mostrar√° la utilidad de la funci√≥n anova. Para esto vamos a utilizar la base de datos **Cars93** del paquete **MASS.** El objetivo es construir un modelo para explicar la media del Price de los autos en funci√≥n de las variables Horsepower, Type y Weight.

----

La soluci√≥n de este ejercicio tendr√° dos partes, en la primera se construir√°n varios modelos, iniciando con uno sin covariables (mod0) hasta uno con todas las covariables (mod3). En la segunda parte se analizar√° el modelo con todas las covariables directamente.


```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE, fig.height=4}
library(MASS)

mod0 <- lm(Price ~ 1, data=Cars93)
mod1 <- lm(Price ~ Horsepower, data=Cars93)
mod2 <- lm(Price ~ Horsepower + Type, data=Cars93)
mod3 <- lm(Price ~ Horsepower + Type + Weight, data=Cars93)

anova(mod0, mod1)

anova(mod1, mod2)

anova(mod2, mod3)

```

---


# Anova



* De la salida anterior se tiene que el valor-P es < 2.2e-16 y por lo tanto se concluye que la variable Horsepower mejora el modelo (la misma conclusi√≥n se pudo obtener del summary).


* De la salida anterior se tiene que el valor-P es 0.01337 y por lo tanto se concluye que el modelo mod2 con dos covariables explica mejor la variable Price.


* De esta √∫ltima salida vemos que el valor-P es 0.648, esto indica que la inclusi√≥n de la variable Weight no mejora el modelo mod2 (la misma conclusi√≥n se pudo obtener del summary).


----

.pull-left[

En esta segunda parte del ejemplo se usar√° la funci√≥n anova directamente sobre el modelo completo mod3, a continuaci√≥n los resultados.

```{r, eval=FALSE, echo=TRUE}
anova(mod3)
```

]

.pull-right[

El valor-P reportado en la primer l√≠nea es < 2e-16, esto indica el modelo con Horsepower es mejor que el modelo sin covariables; el valor-P de la segunda l√≠nea es 0.01411, esto indica que es mejor un modelo con las covariables Horsepower y Type; por √∫ltimo el valor-P de la tercer l√≠nea es 0.64803, esto indica que la variable Weight no mejora el modelo, es decir, que es mejor un modelo con solo Horsepower y Type.

]

---


# Repaso de la regresi√≥n polinomial


Una marca de coches quiere generar un modelo de regresi√≥n que permita predecir el consumo de combustible (mpg) en funci√≥n de la potencia del motor (horsepower).


```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE, fig.height=4}

library(ISLR)
attach(Auto)
plot(x = horsepower, y = mpg, main = "Consumo vs potencia motor", pch = 20,
     col = "grey")

attach(Auto)
modelo_lineal <- lm(formula = mpg ~ horsepower, data = Auto)
summary(modelo_lineal)


plot(x = horsepower, y = mpg, main = "Consumo vs potencia motor", pch = 20,
     col = "grey")
abline(modelo_lineal, lwd = 3, col = "red")


modelo_pol2 <- lm(formula = mpg ~ horsepower + I(horsepower^2), data = Auto)
# El uso de I() es necesario ya que el s√≠mbolo ^ tiene otra funci√≥n dentro de las formula de R

modelo_cuadratico <- lm(formula = mpg ~ poly(horsepower, 2), data = Auto)
summary(modelo_cuadratico)

par(mfrow = c(2, 2))
plot(modelo_cuadratico)


anova(modelo_lineal, modelo_cuadratico)


library(ggplot2)
ggplot(Auto, aes(x = horsepower, y = mpg)) +
    geom_point(colour = "grey") +
    stat_smooth(method = "lm", formula = y ~ poly(x, 2), colour = "red") +
    labs(title = "Consumo vs potencia motor") +
    theme_bw()


```


---



# Regresi√≥n con variables categ√≥ricas



```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE, fig.height=4}

library(readxl)
library(tidyverse)


Salaries <- read_excel("Datos/salaries.xlsx", sheet=1)

names(Salaries)

ggplot(Salaries, aes(x=yrs.since.phd, y=salary))+
  geom_point()

cor(Salaries$yrs.since.phd, Salaries$salary)


modelo1<-lm(salary ~ yrs.since.phd, Salaries)

summary(modelo1)


plot(modelo1)

# Varianza constante
library(lmtest)
bptest(modelo1)


# Normalidad
shapiro.test(modelo1$residuals)


# Y que pasa si queremos incluir el sexo y el rank como predictoras?

modelo2<-lm(salary ~ yrs.since.phd + yrs.service
            + as.factor(sex)+ as.factor(rank), Salaries)

summary(modelo2)



#######CODIGO PARA CAMBIAR POBLAC

Salaries$rank2 <-factor(Salaries$rank)

levels(Salaries$rank2)

Salaries$rank2 <- relevel(Salaries$rank2, ref = 3)

levels(Salaries$rank2)





```







---




# Predicci√≥n



La funci√≥n **predict** es una funci√≥n gen√©rica, que se puede aplicar a un modelo ajustado para obtener los valores de $\hat{y}$. Abajo se muestra la estructura de la funci√≥n predict con la lista de sus argumentos.


----

```{r, eval=FALSE, echo=TRUE}

predict.lm(object, newdata, se.fit = FALSE, scale = NULL, df = Inf, 
    interval = c("none", "confidence", "prediction"), 
    level = 0.95, type = c("response", "terms"), 
    terms = NULL, na.action = na.pass, pred.var = res.var/weights, 
    weights = 1, ...) 

```

----

Suponga que queremos ajustar un modelo de regresi√≥n para explicar el n√∫mero de trabajadores empleados (Employed) en funci√≥n de las covariables Unemployed, Armed.Forces y Year del conjunto de datos longley. Luego de ajustar el modelo queremos predecir el valor de $E(Employed | x= x_0)$ en dos situaciones:


* A√±o 1963 con 420 desempleados y 270 personas en fuerzas armadas.
* A√±o 1964 con 430 desempleados y 250 personas en fuerzas armadas.


---

# Predicci√≥n


**Soluci√≥n**


> Estimar el modelo

```{r, echo=TRUE}
mod <- lm(Employed ~ Unemployed + Armed.Forces + Year, data=longley)
mod

```


---

# Predicci√≥n


**Soluci√≥n**


> Ahora, construir un nuevo marco de datos con la informaci√≥n de las covariables, usando los mismos nombres y los mismos tipos de variables (cuali o cuanti) que en el conjunto de datos con el cual se entren√≥ el modelo.


```{r, echo=TRUE}
nuevo <- data.frame(Year=c(1963, 1964),
                    Unemployed=c(420, 430),
                    Armed.Forces=c(270, 250))
nuevo
```

---

# Predicci√≥n


**Soluci√≥n**

Ahora ya podemos usar la funci√≥n **predict** para obtener lo solicitado.

```{r, echo=TRUE}

predict(object=mod, newdata=nuevo)


```

---

### Intervalo de confianza para la respuesta media $E(y|x_0)$

$$\hat{\mu}_{y|x_0} \pm t_{\alpha/2, n-p} \sqrt{MSE \left( \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{\sum(x_i-\bar{x})} \right)  }$$


<br><br><br>


### Intervalo de confianza para la preedicci√≥n de nuevas observaciones

$$\hat{y_0} \pm t_{\alpha/2, n-p} \sqrt{MSE \left( 1 + \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{\sum(x_i-\bar{x})} \right)  }$$

---

# Ejemplo


Ajustar un modelo de regresi√≥n lineal simple para explicar la Resistencia de una soldadura en funci√≥n de la Edad de la soldadura

```{r, echo=TRUE}
Resistencia <- c(2158.7,1678.15 ,2316 ,2061.3  ,2207.5  ,1708.3 ,1784.7  ,2575 ,2357.9  ,2256.7 
,2165.2 ,2399.55 ,1779.8  ,2336.75 ,1765.3  ,2053.5  ,2414.4  ,2200.5  ,2654.2  ,1753.7) 

Edad <- c( 15.5,23.75 ,8 ,17 ,5.5,19,24,2.5,7.5,11,13,3.75,25,9.75,22,18,6,12.5,2,21.5)


datos <- data.frame(Resistencia , Edad)

mod1 <- lm(Resistencia ~ Edad, data=datos)
mod1

```

* Obtener el IC al 95% para $E(y|x_0)$ cuando $x_0 = Edad =13.3625$
* Obtener el IC al 95% para $\hat{y}$ cuando $x_0 = Edad =10$



---

# Ejemplo

Para obtener el IC al 95% para $E(y|x_0)$ cuando $x_0 = Edad =13.3625$ semanas se usa el siguiente c√≥digo


```{r, echo = TRUE}
nuevo <- data.frame(Edad=13.3625)
predict(object=mod1, newdata=nuevo, interval="confidence", level=0.95)

```


----

Para obtener el IC al 95% para $\hat{y}$ cuando $x_0 = Edad =10$


```{r, echo = TRUE}
nuevo <- data.frame(Edad=10)
predict(object=mod1, newdata=nuevo, interval="prediction", level=0.95)

```


---

# Ejemplo

Ahora vamos a obtener todos los IC  $\hat{y}$ y los vamos a almacenar en el objeto **future_y** que luego luego vamos a agregar al marco de datos original.

Con el c√≥digo mostrado a continuaci√≥n se construye el diagrama de dispersi√≥n y se agrega la l√≠nea de regresi√≥n (en azul) y los IC para $E(y|x_0)$ (en rosado) por medio de *geom_smooth*. Los IC para $\hat{y}$ (en rojo) se agregan por medio de *geom_line*

.pull-left[

```{r, echo=TRUE, eval=FALSE}
future_y <- predict(object=mod1, interval="prediction", level=0.95)
nuevos_datos <- cbind(datos, future_y)

library(ggplot2)
ggplot(nuevos_datos, aes(x=Edad, y=Resistencia))+
    geom_point() +
    geom_line(aes(y=lwr), color="red", linetype="dashed") +
    geom_line(aes(y=upr), color="red", linetype="dashed") +
    geom_smooth(method=lm, formula=y~x, se=TRUE, level=0.95, col='blue', fill='pink2') +
    theme_light()

```

]



.pull-right[

```{r, echo=FALSE, eval=TRUE}
future_y <- predict(object=mod1, interval="prediction", level=0.95)
nuevos_datos <- cbind(datos, future_y)

library(ggplot2)
ggplot(nuevos_datos, aes(x=Edad, y=Resistencia))+
    geom_point() +
    geom_line(aes(y=lwr), color="red", linetype="dashed") +
    geom_line(aes(y=upr), color="red", linetype="dashed") +
    geom_smooth(method=lm, formula=y~x, se=TRUE, level=0.95, col='blue', fill='pink2') +
    theme_light()

```


]







---

class: inverse, center, middle
background-color: #122140

.pull-left[

.center[
<br><br>

# Gracias!!!

<br>



### ¬øPreguntas?

<br>


```{r qr, echo=FALSE, fig.align="center", out.width="49%"}
knitr::include_graphics("img/qr-code.png")
```


]


]


.pull-right[

<br> 
<br> 
<img style="border-radius: 50%;" src="img/avatar.png"
width="150px"
/>

### [www.joaquibarandica.com](https://www.joaquibarandica.com)

`r icon("envelope")` orlando.joaqui@correounivalle.edu.co

<img src="img/Logo.jpg" width="120%">

]


<br><br><br>









